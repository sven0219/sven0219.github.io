---
title: 【Python3WebSpider02】爬虫基本原理
tags:
  - Python
  - 爬虫
  - 记录
id: '12129'
categories:
  - - skills
date: 2020-08-06 19:06:33
---

# 爬虫基本原理

## 爬虫概述

获取并提取和保存信息的自动化程序

#### 1\. 获取网页

爬虫首先要做的是获取网页的源代码。源代码里包含了网页的部分有用信息，获取之后再提取想要的信息。

#### 2\. 提取信息

获取网页源代码后，接下来就是分析网页源代码，从中提取我们想要的数据。首先，最通用的方法便是采用正则表达式提取，这是一个万能的方法，但是在构造正则表达式时比较复杂且容易出错。 另外，由于网页的结构有一定的规则，所以还有一些根据网页节点属性、CSS选择器或XPath来提取网页信息的库，如Beautiful Soup、pyquery、lxml等。使用这些库，我们可以高效快速地从中提取网页信息，如节点的属性、文本值等 提取信息是爬虫非常重要的部分，它可以使杂乱的数据变得条理清晰，以便我们后续处理和分析数据。

#### 3\. 保存数据

提取信息后，一般会将提取到的数据保存到某处以便后续使用。数据的持久化可以有多种方式，简单点的保存为 txt 或者 json 文办，也可以保存到数据库。

#### 4\. 自动化程序

上述几个操作可以手工处理，但是在面临大量数据或者想快速抓取数据的时候，还是需要借助程序。爬虫就是爬取数据的自动化程序，就可以在抓取的过程中进行各种异常处理、错误重试等操作。

## 能抓哪些数据

在网页中我们能看到各种各样的信息，最常见的便是常规网页，它们对应着HTML代码，而最常抓取的便是HTML源代码。 另外，可能有些网页返回的不是HTML代码，而是一个JSON字符串（其中API接口大多采用这样的形式），这种格式的数据方便传输和解析，它们同样可以抓取，而且数据提取更加方便。 此外，我们还可以看到各种二进制数据，如图片、视频和音频等。利用爬虫，我们可以将这些二进制数据抓取下来，然后保存成对应的文件名。 另外，还可以看到各种扩展名的文件，如CSS、JavaScript和配置文件等，这些其实也是最普通的文件，只要在浏览器里面可以访问到，就可以将其抓取下来。 上述内容其实都对应各自的URL，是基于HTTP或HTTPS协议的，只要是这种数据，爬虫都可以抓取。